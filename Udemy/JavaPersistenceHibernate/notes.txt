Granularity: Is the extent to which a system could be broken down into small parts.

	coarse-grained: Contains a lot of details: Example: Person
	fine-granined: Contains specific information: Example: Address
	
	Object model: Various levels of granularity
	Relational Model: 2 levels of granularity (columns and tables)
	Object model is more granular than the relational model. 
	
Inheritance
	
	Object model: Inheritance
	Relational model: No inheritance

Identity

	Object model: object identity (foo == bar) and object equality (foo.equals(bar))
	Relational model: Primary key.
	
Associations

	Object model: Object references (directional)
	Relational model: Foreign key (non - directional)

Data Navigation

	Object model: Navigate through associations
	Relational model: SQL
	
	
Aggregation: Indicates a relationship between a whole and its parts. Example: Music Band (whole) Artist (part). When the whole is destroyed its parts are not destroyed with it.
Composition: Composition is a strong form of aggregation. Each part may belong to only one whole (no sharing). Example: House (whole) Rooms(part) When the whole is destroyed its parts are also destroyed with it.

An object of entity type has its own database identity (primary key value)

An object of value type has no database identity (primary key value), it belongs to an entity

A component is a part of a whole in such a way that if the whole is destroyed, all its parts are also destroyed with it.
Each component may belong to only one whole (it is not shared).
A component is a contained object that is persisted as a value type.
A component has no database identity.

Associations

	Cascading the Persist Operation = Transitive Persistance
	If the association is bidirectional, one of the sides (and only one) has to be the owner of the relationship - The owner of the relationship is responsible for the association column(s) update.
	Many side in a OneToMany bidirectional relationship is (almost) always the owner side. In this case the One side is called inverse end.
	In a bidirectional OneToOne relationship to declare a side as not responsible for the relationship, the attribute mappedBy is used.
	In a bidirectional ManyToMany relationship the inverse end is not responsible for the relationship. The inverse end will be ignored when updating the relationship values in the join table.
		When updating the owner, the owner is responsible for the relationship, so it will have the join table updated.
		
Composite Primary Key

	A combination of more than 1 table column that identifies the uniqueness of a record/(database table row)
	No matter how good or natural a composite primary key is, it is not recommended for uniquely identifying a record.
	Not only composite keys, even business keys (e.g ISBN, SSN) are not recommended for uniquely identifying a record. A business key is also called a Natural Key.
	A business key is not just a unique identifier but it also has a business meaning associated with it.
	As a best practice use synthetic identifier. (Identifier with no business meaning)
	
Composite Foreign Key

	When a foreign key is made of a single column we use @JoinColumn
	When a foreign key is made of a multiple columns we use @JoinColumns
	
JPA

	JPA is a Java specification for accessing, persisting, and managing data between Java Objects and a relational database.
	JPA provides guidelines that a framework can implement to be considered JPA compatible.
	In addition to its own "native" API, Hibernate is also an implementation of the Java Persistence API (JPA) specification.

Working with objects

	Transiency object: State is transient which means that is not associated with any database. It's state is going to be lost as soon as it's no longer referenced by any other object.
	
	Persistent object: Object that is associated with an entity manager. It's an object with a database identity. It may be an object created by an application or it may be an object
		created by calling a lookup method. When an object becomes persistent it's going to be managed by the entity manager for the duration of the transaction.
		A persistent object is an object that not only exist in Java memory but is also associated with an entity manager so that when the transaction is committed the state of that object 
		will be persisted to the database.
	
	Persistence context: It is a forest level cache and it has its own non shared database connection and it is this persistent contact that checks whether an object has got dirty or modified
		by the application and updates those changes where the transaction is committed. Whenever you create a new hibernate session object or an answer as a manager it creates a persistence context.
		Each entity manager has a persistence context. When the object is detached it is no longer managed by the entity manager. You can re attach an object by using the merge method.
		To manually detach a persistent object you just need to call the detach method.
	
Caching objects
	
	Cache: Is a copy of data, copy meanining pulled from but living outside the database.
	
	First level caching: 	scope ---> EntityManager
	Second level caching: 	scope ---> EntityManagerFactory
	
SQL Joins

	Inner join
		
		select * from tableA inner join tableB on tableA.name = tableB.name
		
		Inner join keyword returns only the rows that match in both table A and table B.
		
	Left outer join 
		
		select * from tableA left outer join tableB on tableA.name = tableB.name
		
		Left outer join keyword returns all the rows from the left table with the matching rows (where available) in the right table.
		If there is no match, the right side will contain null.
		
Lazy Fetching
	
	A collection is fetched when the application invokes an operation upon that collection. By default, collection associations (@OneToMany and @ManyToMany) are lazily fetched.
	It is not going to work outside of the scope of an entity manager.
	
Eager Fetching

	By default single point associations (@OneToOne and @ManyToOne) are eagerly fetched.
	
Equals and Hashcode

	If two objects are equal, then their hashcode values must also be equal.
	
	Whenever you implement equals(Object), you must also implement hashcode()
	
JPQL

	Queries entities.
	Case sensitive.
	A JPQL query is always a valid HQL query, the reverse is not true however.
	
HQL (Hibernate Query Language)


Inheritance Mapping and Polymorphic Queries
	
	Single_Table strategy
	
		The class hierarchy is represented in one table. A discriminator column identifies the type and the subclass.
		Good for polymorphic queries; no joins required.
		All the properties in subclass must not have not-null constraint.
		Good performance for derived class queries; no joins required.
		
	Joined strategy
	
		The superclass has a table and each subclass has a table that contains only un inherited properties (the subclass tables have a primary key that is a foreign key of the superclass).
		Poor performance for polymorphic queries.
		All the properties in superclasses may have not-null constraint.
		Not too bad performance for derived class queries.
		
	Table per class
	
		Each table contains all the properties of the concrete class and also the properties that are inherited from its superclasses.
		The database identifier and its mapping have to be present in the superclass, to be shared in all subclasses and their tables.
		Not good for polymorphic queries.
		Good performance for derived class queries.
		
N + 1 Selects Problem

	Remember:
	
		By default single point associations (@OneToOne and @ManyToOne) are eagerly fetched
		By default collection associations (@OneToMany and @ManyToMany) are lazily fetched
		
		Student and Guide example:
		
			select student from Student student;
			
				1 select for all the parent objects
				1 select for each child object
		
			select student from Student student left join fetch student.guide;
			
				Resolved.
				
		How to solve:
		
		1. Change the fetching strategy of your single point associations (@ManyToOne and @OneToOne) from Eager to Lazy.
		2. Write the query based on the requirements (e.g using left fetch join to load the child objects eagerly)
		3. When number of parents becomes higher to change the fetching strategy to eager in order to have small n + 1 statements. 
		4. The previous recommendation still not good enough for performance, consider Batch Fetching implementation.
		
Batch Fetching

	@BatchSize
	
	Batch fetching is an optimization of the lazy fetching strategy.
	

Merging Detached Objects
	
	1. Using detached objects, cascade={CascadeType.MERGE} and entityManager.merge(entityObj);
	2. Using extended persistence context, cascade={CascadeType.MERGE} not needed.
	
Optimistic Locking and Versioning

	Last commit wins issue
	
	@Version
	private Integer version
	
	Hibernate is going to check for the version number at each update.
	An exception will be thrown, to prevent a lost update, if Hibernate does not find the in-memory version of an entity to be same as the database version (current version)
	
	Implementing a business process that spans through multiple transactions should be done using the versioning strategy, to prevent lost updates.
	
	Optimistic Locking: Official name of the versioning strategy to prevent lost updates. No database locking.
	Pessimistic Locking: Database locking. Could be used only withing a single transaction.
	
	Conversation
	
		1. Loading objects.
		2. Modyfing loaded objects.
		3. Storing loaded objects.
		
	Use Versioning strategy to prevent lost updates when implementing a conversation (multiple transactions/[request/response cycles]).
	Use Pessimistic locking only within a single transaction.
	
	When to use Pessimistic locking? When you've got multiple database queries being executed on the same data, within a single transactions.
	
Rules for Isolation Levels

	Isolation level defines the extent to which a transaction is visible to other transactions.
	How and when the changes made by one transaction are made visible to other transactions.
	
	Shouldn't a transaction be completely isolated from other transactions?
	
		Serializable: highest isolation-level; provides full/complete isolation-level. Transactions are executed serialy, one after the other. Transaction2 can be commited until transaction 1 is committed. Slow performance.
		Repeatable_read: Phantom reads are possible. Better performance.
		Read_committed: Un repeatable reads are possible.
		Read_uncommitted: lowest isolation-level: Same as read_commited. Could get rollbacks. Dirty reads are possible. Not recommended.
		
		MySQL supports all 4 isolation levels. Repeatable_read (default)
		Oracle supports Serializable and Read_committed. Read_commited (default)
		
Caching and Object Identity

	A cache is id based.
	With first level cache you are going to get a Repeatable_read even if isolation level is lower than that.
	
Second level caching

	By default, Hibernate does not cache the persistent objects across different EntityManagers.
	Second cache is also called L2 Cache, Shared Data Cache and Shared Cache.
	Hibernate stores data in a Second level cache in a dehydrated way: Guide[2] => ["Ian Lamb", 4000, "2000IM10901", 1]
	
	L2 Cache
	
		Entity Data Cache
		Collection Cache
		Query Result Cache
	
	L2 Cache Implementation
	
		EhCache - Single JVM					
			hibernate-ehcache-4.3.5.jar
		
		TreeCache from JBOSS - Multiple JVMs	
			ehcache-core-2.4.3.jar
			slf4j-api-1.6.1.jar
			slf4j-log4j12-1.6.1.jar
			log4j-1.2.17.jar
			
		ehcache.xml
		
			<?xml version="1.0" encoding="UTF-8" ?>
			<ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				xsi:noNamespaceSchemaLocation="ehcache.xsd">
				<cache name="domain.Guide" 
					maxElementsInMemory="1000" 
					eternal="true" 
					<!-- Configure timeToIdleSeconds and timeToLiveSeconds if there is a probability of more than one user modifying the entity at the same time -->
					timeToIdleSeconds="..."  
					timeToLiveSeconds="..." 
					overflowToDisk="false"
				</cache>
			</ehcache>
		
		 When entities cached in the second level cache are updated, Hibernate invalidates them and add the updated data.
		 
	To manually invalidate the cached data of a persistent class:
	emf.evictEntity(domain.Guide2);		//Invalidate all elements
	emf.evictEntity(domain.Guide2, 2L);	//Invalidate only one element
	
	StatistcsAPI: Monitors the second level cache.
	
	Cache Concurrency Strategy: A cache concurrency strategy defines a transaction isolation level for an entry in a cache region.
		
		@Cacheable uses CacheConcurrencyStrategy.READ_WRITE. Default and it is equivalent to READ_COMMITTED transaction isolation level.
		
		Types
		
			- TRANSACTIONAL: cluster, read-mostly data; equivalent to REPEATABLE_READ
			- READ_WRITE: read mostly data equivalent to READ_COMMITTED
			- NONSTRICT_READ_WRITE : data is hardly ever changes
			- READ_ONLY: data is never modified
		
		
			Single JVM - EhCache
				READ_WRITE
				NONSTRICT_READ_WRITE
				READ_ONLY
				
			Cluster of JVM - TreeCache
				TRANSACTIONAL
				
		@Cacheable does not have an option to configure other CacheConcurrencyStrategy.
		
		@org.hibernate.annotations.Cache(usage=CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
		
	Process Scope - Cluster Scope
	
		Process Scope
			- Single JVM
			- READ_ONLY, NONSTRICT_READ_WRITE, READ_WRITE
			- EhCache
		
		Cluster Scope
			- Cluster of JVMs
			- Transactional
			- TreeCache from JBOSS (Replicated clustered cache)
		
	Caching Associations (in Second level cache)	
		
		By default associated objects are not cached.
		The reason to cache associations is to avoid extra calls to the database.
		The second level caching is enabled not only on the class-by-class basis, but the collection-by-collection basis as well.
		If a persistent object contains associated objects in a collection, the collection can also be cached explicitly.
		
Best practices

	1. Declare identifier properties on persistent classes.
	
	2. Identify natural/business keys.
	
	3. Do not treat exceptions as recoverable.
	
	4. Prefer lazy fetching for associations. If you need to load a collection eagerly use a left join fetch.
	
	5. Prefer bidirectional associations. In a large application, almost all associations must be navigable
		in both directions in queries
		
	6. Use bind variables.
	
		In JDBC always replace non-constant values by ?
		If using JPQL used named parameters
	
	7. Using second level caching for those entity classes that represented
		
		Good candidates: 
		
			Data that changes rarely.
			Noncritical data (for example content management data)
			Data that's local to the application and not modified by other applications.
			
		Bad candidates:
		
			Data taht is updated often.
			Financial data, where decisions must be based on the latest update.
			Data that is shared with and/or written by other applications.
			
	
	