Object Relational Impedance Mismatch

	Granularity: Is the extent to which a system could be broken down into small parts.

		coarse-grained: Contains a lot of details: Example: Person
		fine-granined: Contains specific information: Example: Address
	
		Object model: Various levels of granularity
		Relational Model: 2 levels of granularity (columns and tables)
		Object model is more granular than the relational model. 
	
	Inheritance
	
		Object model: Inheritance
		Relational model: No inheritance

	Identity

		Object model: object identity (foo == bar) and object equality (foo.equals(bar))
		Relational model: Primary key.
	
	Associations

		Object model: Object references (directional)
		Relational model: Foreign key (non - directional)

	Data Navigation

		Object model: Navigate through associations
		Relational model: SQL
	

Mapping Concepts
	
	Aggregation: Indicates a relationship between a whole and its parts. Example: Music Band (whole) Artist (part). 
				 When the whole is destroyed its parts are not destroyed with it.
	
	Composition: Composition is a strong form of aggregation. Each part may belong to only one whole (no sharing). 
			     Example: House (whole) Rooms(part) When the whole is destroyed its parts are also destroyed with it.

	
	Entities and Value Types
	
		An object of entity type has its own database identity (primary key value)

		An object of value type has no database identity (primary key value), it belongs to an entity
		
		String and Integer are value types.

	Component Mapping
	
		A component is a part of a whole in such a way that if the whole is destroyed, all its parts are also destroyed with it.
		Each component may belong to only one whole (it is not shared).
		A component is a contained object that is persisted as a value type.
		A component has no database identity.

	Associations

		Cascading the Persist Operation = Transitive Persistence
		
		If the association is bidirectional, one of the sides (and only one) has to be the owner of the relationship.
		The owner of the relationship is responsible for the association column(s) update.
		
		The "Many side" in a OneToMany bidirectional relationship is (almost) always the owner side. In this case the "One side" is called inverse end.
		
		In a bidirectional OneToOne relationship to declare a side as not responsible for the relationship, the attribute mappedBy is used.
		
		In a bidirectional ManyToMany relationship the inverse end is not responsible for the relationship. The inverse end will be ignored when 
		updating the relationship values in the join table. When updating the owner, the owner is responsible for the relationship, 
		so it will have the join table updated.
		
		The owner of the relationship is the one that has a reference to the foreign key.
		
		Orphaned record is a record whose foreign key value references a non-existent key value.
		
	Derived Identifier
	
		Id that is derived from another entity. It is used only with Single Point Association(OneToOne or ManyToOne).
		Use derived identifier when you want to use a shared primary key.
		
	Composite Primary Key

		A combination of more than 1 table column that identifies the uniqueness of a record/(database table row)
		No matter how good or natural a composite primary key is, it is not recommended for uniquely identifying a record.
		Not only composite keys, even business keys (e.g ISBN, SSN) are not recommended for uniquely identifying a record. 
			A business key is also called a Natural Key.
		A business key is not just a unique identifier but it also has a business meaning associated with it.
		As a best practice use synthetic identifier. (Identifier with no business meaning)
	
	Composite Foreign Key

		When a foreign key is made of a single column we use @JoinColumn
		When a foreign key is made of a multiple columns we use @JoinColumns
	
JPA

	JPA is a Java specification for accessing, persisting, and managing data between Java Objects and a relational database.
	JPA provides guidelines that a framework can implement to be considered JPA compatible.
	In addition to its own "native" API, Hibernate is also an implementation of the Java Persistence API (JPA) specification.
	
	How can we use the Hibernate Non JPA features while using it as a JPA Provider?
	
		We can do that by using the Hibernate Native API accessing the unwrap() method. By using that method we can get access to the
		native Hibernate Session Factory and Session objects.
	
	<persistence-unit name="hibernate-jpa" transaction-type="RESOURCE_LOCAL">

		transaction-type="RESOURCE_LOCAL": You are responsible for creating an EntityManager
		transaction-type="JTA": An EntityManager can be supplied to you by EJB container of an application server (Glassfish for example)
		


Transient object: 
	
	State is transient which means that is not associated with any database. It's state is going to be lost as soon as it's no longer 
	referenced by any other object.
	
Persistent object: 
	
	- Object that is associated with an entity manager. It's an object with a database identity.
	- It may be an object created by an application or it may be an object created by calling a lookup method. 
	- When an object becomes persistent it's going to be managed by the entity manager for the duration of the transaction.
	- A persistent object is an object that not only exist in Java memory but is also associated with an entity manager so that 
		when the transaction is committed the state of that object will be persisted to the database.
	
Persistence context: 
		
	- It is a first level cache and it has its own non shared database connection and it is this persistent context that checks 
	whether an object has got dirty or modified by the application and updates those changes where the transaction is committed. 
		
	- Whenever you create a new hibernate session object or an entity manager it creates a persistence context.
	- Each entity manager has a persistence context. When the object is detached it is no longer managed by the entity manager. 
	- You can re attach an object by using the merge method. To manually detach a persistent object you just need to call the detach method.
						 
	- It is a service that remembers all the modifications and state changes made to your data in a particular unit of work.
		
	Types:
						 
		- Application Managed
						 
				EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory(PERSISTENCE_UNIT_NAME);
				EntityManager entityManager = entityManagerFactory.createEntityManager();
				EntityTransaction entityTransaction = entityManager.getTransaction();
				try {
						entityTransaction.begin();
            
						entityTransaction.commit();
					} catch (Exception ex) {
						if (entityTransaction != null) {
							entityTransaction.rollback();
						}
						ex.printStackTrace();
					} finally {
						entityManager.close(); // you create it, you close it
					}	
							
		- Container Managed (created and managed by an application server)
						
				@Stateless
				public class MyEjb implements MyEjbInterface {
								
					@PersistenceContext(unitName = "myPersistenceUnit")
					private EntityManager entityManager;			
						// other stuff
					}
						
						Persistence Context provides:
						
							1. Automatic Dirty Checking
							2. First Level Cache
							3. Repeatable reads
							4. Guaranteed Scope of Objects Identity

	Automatic Dirty Checking: 
		
		- It is performed by the persistence context. If there is an object already loaded in the persistence context Hibernate will create a 
		snapshot of it so it can perform comparisons. 
		
		- If we get an object, a select statement will be issued against the database and the object will be retrieved and placed in the Persistence Context 
		and it will have a persistence state. (if the object is already in the Persistence Context there is no need of a select statement)
							  
		- If the state of the object is modified when we commit the transaction, Hibernate will compare the snapshot against the object state 
		and it will perform an update statement.
		
		- How to force dirty checking synchronization?
							  
			flush() method will flush changes to the database without the need of commit.
					
	Guaranteed Scope of Objects Identity:
							  
		The persistence context will ensure that will have only one object representing one database row. 
							  
		Dirty checking with snapshots is time consuming. Hibenate does give you an extension point if you want to customize the dirty checking strategy. 
		We can do that by implementing the CustomEntityDirtinessStrategy interface:
							  
			public class MyCustomEntityDirtinessStrategy implements CustomEntityDirtinessStrategy {
				// override methods
			}
								
		Then we need to configure the persistence.xml file by adding:
							  
			<property name = "hibernate.entity_dirtiness_strategy" value = "MyCustomEntityDirtinessStrategy" />
								
							 
							
	Repeatable read: Gives you the same result for the same query even if there is an update in the database.
							
	Refresh() method
							
		If an object is updated but the database info is different and you want to work with fresh data you can 
		use the entityManager.refresh() method and pass the reference of the object as argument.
		This will issue a new select statement and it will override any changes that you have made to the object.
								
	Clear() method
							
		The entityManager.clear() method will detach all the objects of the persistence context.
		
	Detach() method
	
		When the object is detached it is no longer managed by the entity manager. To manually detach a persistent object 
		you just need to call the detach method.
	
	Merge() method
	
		You can re attach an object to the persistence context by using the merge method. 
							
	GetReference() method
	
		If you want to load an entity instance without accessing the database you can use getReference() method.
		You get an uninitialize proxy object. It does not issue a select statement. A proxy get initialize as soon as we call any of the methods 
		to access any of its data attributes. You can also use the Hibernate.initialize() method. The proxy that you get is in the persistent state.
		
			Student student = entityManager.getReference(Student.class, 3L);
			
				String studentName = student.getName(); // initialization
				Hibernate.initialize(student); // initialization
	
	Proxy

		Initialize a collection proxy:

			- Iterating through the elements 

				for (Student student : students) {...}	
			
			- Invoke one of the collection management operations

				- contains(Object o)
				- size()

	Making data transient
		
		Code
		
			Student student = entityManager.find(Student.class, 3L);
			
			// Even if me remove the student from the persistence context we still having its data. 
			// This won't have any impact on the id of the removed student
			entityManager.remove(student);
		
			Long id = student.getId // you will get a value, it will not be null
		
			entityManager.persist(student); // this code will move back the student to the persistence state. The deletion will be cancelled.
		
			entityManager.getTransaction().commit(); // no delete statement will be issued
	
		When we persist the remove state of the student it will not have any impact on the id of the object. If we want to save the student with a 
		different id value we need to persist a transient student:
		
			The id of a transient student is null.
			
			In the persistence.xml we need to add this configuration:
				
				<!-- Reset identifier value (from long to null) after removal of an entity instance -->
				<property name="hibernate.use_identifier_rollback" value="true" />
				
			Then when calling entityManager.remove(student); it will move the object out of the persistence context and the reference will no longer
			have an id. The id will be set to null. Then:
			
				Student student = entityManager.find(Student.class, 3L);
				entityManager.remove(student);
		
				Long id = student.getId // id will be null
		
				entityManager.persist(student); // Exception
		
			To resolve this we need to close the persistence context and use a new one:
				
				EntityManagerFactory entityManagerFactory = Persistence.createEntityManagerFactory("myPersistenceUnit");
				EntityManager entityManager = entityManagerFactory.createEntityManager();
				entityManager.getTransaction().begin();
				Student student = entityManager.find(Student.class, 3L);
				entityManager.remove(student);
				Long id = student.getId // id will be null
				entityManager.getTransaction().commit();
				entityManager.close();
				
				EntityManager entityManager2 = entityManagerFactory.createEntityManager();
				entityManager2.getTransaction().begin();
				entityManager2.persist(student); // Student student2 = entityManager2.merge(student);
				entityManager2.getTransaction().commit();
				entityManager2.close();
	
	Persist vs Merge
	
		entityManager.persist(transientStudent); 
		
			The transient object will be moved from the transient state to the persistence state.

		entityManager.merge(transientStudent); 
				
			Hibernate checks whether there is already an object being managed in the persistence context whose id is same as the id of
			the object that you passed into it. In this case it does not move the transient state to persistence state instead, it creates
			a new object in the persistence state.
			
			
Caching objects
	
	Cache: Is a copy of data, copy meanining pulled from but living outside the database.
	
	First level caching: 	scope ---> EntityManager
	Second level caching: 	scope ---> EntityManagerFactory
	
	Cache does not shrink automatically. 
	
		Keep the size of the cache to the necessary minimum.
		Check that your queries return only data that you need.
		
	
SQL Joins

	Inner join
		
		select * from tableA inner join tableB on tableA.name = tableB.name
		
		Inner join keyword returns only the rows that match in both table A and table B.
		
	Left outer join 
		
		select * from tableA left outer join tableB on tableA.name = tableB.name
		
		Left outer join keyword returns all the rows from the left table with the matching rows (where available) in the right table.
		If there is no match, the right side will contain null.
		
Lazy Fetching
	
	A collection is fetched when the application invokes an operation upon that collection. By default, collection associations 
	(@OneToMany and @ManyToMany) are lazily fetched.
	
	It is not going to work outside of the scope of an entity manager.
	
Eager Fetching

	By default single point associations (@OneToOne and @ManyToOne) are eagerly fetched.
	
Equals and Hashcode

	If two objects are equal, then their hashcode values must also be equal.
	
	Whenever you implement equals(Object), you must also implement hashcode()
	
JPQL (Java Persistence Query Language)

	- Queries entities.
	- Case sensitive.
	- A JPQL query is always a valid HQL query, the reverse is not true however.
	- Join fetch: Useful when you need to reduce the number of queries against the database.
	
SQL is case insensitive
	
	Guide=guide=GUIDE=Guide
	guide.id=guide.Id=guide.ID
	
HQL (Hibernate Query Language)
	
	You can use it when you are are using native Hibernate API
	You can also use it when you are using Hibernate as a JPA provider
	
Flushing
	
	- When the transactions commits.
	
	- By using the flush method we can force dirty checking and update database.
	
	- Before the execution of a query the flushing happens automatically because that is the default behavior (entityManager.setFlushMode(FlushModeType.AUTO)).
		
		Example:
		
			entityTransaction.begin();
            Student3 student = entityManager.find(Student3.class, 3L); // in database is Oscar Santamaria
            student.setName("Oscar Venegas");
            String selectStatement = "select s.name from Student3 s where s.id = :id";
            
			/* Synchronizes/flushes persistence context before the query is executed */
            Query query = entityManager.createQuery(selectStatement).setParameter("id", 3L);
            String name = (String) query.getSingleResult();
            entityTransaction.commit(); // no update issued
	
	- We can change the default to entityManager.setFlushMode(FlushModeType.COMMIT).
	
Criteria API

	1. Programmatic Query Construction

		Compiler checks for errors: 
		
			select g from Guide join fetch g.students student; 	 ---> syntactically incorrect
			select g from Guide g join fetch g.students student  ---> syntactically correct

	2. Type Safety

		TypedQuery<T> typedQuery = em.createQuery(CriteriaQuery);
		List<T> result = typedQuery.getResultList();

		TypedQuery<String> typedQuery = em.createQuery("select g.name from Guide g", String.class);
		List<String> names = typedQuery.getResultList();

			Metamodel of Guide entity
				
				Guide_.name

				https://docs.jboss.org/hibernate/orm/current/topical/html_single/metamodelgen/MetamodelGenerator.html

Inheritance Mapping and Polymorphic Queries
	
	Single_Table strategy
	
		The class hierarchy is represented in one table. A discriminator column identifies the type and the subclass.
		Good for polymorphic queries; no joins required.
		All the properties in subclass must not have not-null constraint. (This could be negative)
		Good performance for derived class queries; no joins required.
		
	Joined strategy
	
		The superclass has a table and each subclass has a table that contains only un inherited properties (the subclass tables have a primary key that is a foreign key of the superclass).
		Poor performance for polymorphic queries.
		All the properties in superclasses may have not-null constraint.
		Not too bad performance for derived class queries.
		
	Table per class
	
		Each table contains all the properties of the concrete class and also the properties that are inherited from its superclasses.
		The database identifier and its mapping have to be present in the superclass, to be shared in all subclasses and their tables.
		Not good for polymorphic queries.
		Good performance for derived class queries.

	@MappedSuperClass

		Can't run polymorphic queries like "select account from Account account"

		@MappedSuperclass
		public class Account {

    		@Id
    		@GeneratedValue(strategy= GenerationType.IDENTITY)
    		private Long id;

    		private String owner;

    		private BigDecimal balance;

    		public void setOwner(String owner) {
        		this.owner = owner;
    		}

    		public void setBalance(BigDecimal balance) {
        		this.balance = balance;
    		}
		}
			
		@Entity
		@Table(name="credit_account")
		public class CreditAccount extends Account {

    		@Column(name="credit_limit")
    		private BigDecimal creditLimit;

    		public void setCreditLimit(BigDecimal creditLimit) {
        		this.creditLimit = creditLimit;
    		}

		}

Pre Insert Identifier Generation

	Sequence: Generates unique sequential numeric values. MySQL does not provide native support for sequences.

	SQL

		create sequence my_sequence
			minvalue 0
			start 1
			increment 1
		;

		select nextval('my_sequence');

	There are two ways that the id value can be assigned to an entity.

		Before an insert is issued. (pre insert identifier generation)

			- That happens with the GenerationType.SEQUENCE and GenerationType.TABLE strategies.
			- Here an insert statement is issued when calling entityTransaction.commit() not entityManager.persist(student). That happens because hibernate tries to optimize sql statements.
			- The difference between GenerationType.SEQUENCE and GenerationType.TABLE is that GenerationType.TABLE uses row table lock. With GenerationType.TABLE a table always is going to 
				be created to store the next value of a sequence.
            
		After an insert is issued.

			If we use GenerationType.IDENTITY it uses auto-incremented column value so the identifier id is available at post-insert.
			Insert statement is issued when calling entityManager.persist(student).

		GenerationType.AUTO in hibernate 5 will use Sequence as default id generation strategy. Since MySQL does not support sequences it will choose Table strategy underneath the hood.
		
N + 1 Selects Problem

	Remember:
	
		By default single point associations (@OneToOne and @ManyToOne) are eagerly fetched
		By default collection associations (@OneToMany and @ManyToMany) are lazily fetched
				
		How to solve:
		
		1. Change the fetching strategy of your single point associations (@ManyToOne and @OneToOne) from Eager to Lazy.
		2. Write the query based on the requirements (e.g using left fetch join to load the child objects eagerly)
		3. When number of parents becomes higher the select statement will be huge. If that is the case, think on changing the fetching strategy back to eager in order 
			to have small n + 1 statements. 
		4. The previous recommendation still not good enough for performance, consider Batch Fetching implementation.
		
Batch Fetching

	- @BatchSize annotation
	- Batch fetching is an optimization of the lazy fetching strategy.
	- Using Batch Fetching, Hibernate can load several uninitialized proxies, even if just one proxy is accessed.
	

Merging Detached Objects
	
	1. Using detached objects, cascade={CascadeType.MERGE} and entityManager.merge(entityObj);
	2. Using extended persistence context, cascade={CascadeType.MERGE} not needed.

	Why do we need to detach objects instead of modifying them while they are associated with a persistence context?

		In a multiuser application where there are so many users using the app we do not usually maintain a database transaction
		across user interactions. Users take a lot of time thinking on the modifications. For scalability reasons we must keep 
		the database transactions short and release database resources as soon as possible.

		We could do this modifications while having them associated with the persistence context but the db connection needs to remain
		disconnected while the objects are being modified. We do that by extending the persistence context. We will be having
		one persistence context but mutiple transactions across user interaction and the object modifications will be done while 
		there is no database connection. If we extend the persistence context Merge operation is not needed since we will not have
		detached objects to merge.
	
Identity of Detached Objects

	Detached objects (even with same data) from different persistence contexts are not equal unless we make them equal by
	overriding the default implementation of equals() and hashcode() methods.

	Whenever you work with detached objects and you test them for equality, you override the equals() and hashcode() methods
	for your mapped entity.

	Using database ids for comparing equality is discouraged is because database identities are not assigned until an object becomes persistent.
	So if you're working with a transient object whose id value is null, it'll cause you a problem.

	
Optimistic Locking and Versioning

	Without Optimistic Locking we have the "Last commit wins" issue. Optimistic Locking is the official name of the Versioning Strategy.
	We are not expecting the "last updates" to happen very often. 

	/* Needs an alter table statement */
	@Version
	private Integer version

	/* Better to use this right from the begining */
	@Column(columnDefinition = "integer DEFAULT 0", nullable = false)
    @Version
    private Integer version;
	
	Hibernate is going to check for the version number at each update.
	An exception will be thrown, to prevent a lost update, if Hibernate does not find the in-memory version of an entity to be same as the database version (current version)
	
	Implementing a business process that spans through multiple transactions should be done using the versioning strategy, to prevent lost updates.
	
	Optimistic Locking: Official name of the versioning strategy to prevent lost updates. No database locking.
	Pessimistic Locking: Database locking. Could be used only withing a single transaction.

	A database lock is used to lock some data in a database. It's basically used to prevent two or more database users from updating the same exact piece of data
	at the same exact time.
	
	Conversation
	
		1. Loading objects.
		2. Modyfing loaded objects.
		3. Storing loaded objects.
		
	Usage:

		- Use Versioning strategy to prevent lost updates when implementing a conversation (multiple transactions/[request/response cycles]).
		
		- Use Pessimistic locking only within a single transaction. When you've got multiple database queries being executed on the same data, within a single transaction.
		Actually, you would not be using pessimistic locking too often in your multi-user applications as holding database logs could hurt the scalability of an application.
		The longer you hold a database lock, the greater the risk of a bad scalability.

			LockModeType.PESSIMISTIC_WRITE: It will not allow other transactions or users to even read the data that is being locked. 
        	LockModeType.PESSIMISTIC_READ: Other users will be able to read the data is being locked.

		- If we use database locks we are being pessimistic since while we are working on some data some of the users might actually update that data in the database.
	
Rules for Isolation Levels

	Isolation level defines the extent to which a transaction is visible to other transactions.
	How and when the changes made by one transaction are made visible to other transactions.
	
	Shouldn't a transaction be completely isolated from other transactions?
	
		Serializable: highest isolation-level; provides full/complete isolation-level. Transactions are executed serialy, one after the other. Transaction2 can be commited until transaction 1 is committed. Slow performance.
		Repeatable_read: Phantom reads are possible. Better performance.
		Read_committed: Un repeatable reads are possible.
		Read_uncommitted: lowest isolation-level: Same as read_commited. Could get rollbacks. Dirty reads are possible. Not recommended.
		
		MySQL supports all 4 isolation levels. Repeatable_read (default)
		Oracle supports Serializable and Read_committed. Read_commited (default)
		
Caching and Object Identity

	A cache is id based.
	With first level cache you are going to get a Repeatable_read even if isolation level is lower than that.
	
Second level caching

	By default, Hibernate does not cache the persistent objects across different EntityManagers.
	Second cache is also called L2 Cache, Shared Data Cache and Shared Cache.
	Hibernate stores data in a Second level cache in a dehydrated way: Guide[2] => ["Ian Lamb", 4000, "2000IM10901", 1]
	
	L2 Cache
	
		Entity Data Cache
		Collection Cache
		Query Result Cache
	
	L2 Cache Implementation
	
		EhCache - Single JVM					
			hibernate-ehcache-4.3.5.jar
		
		TreeCache from JBOSS - Multiple JVMs	
			ehcache-core-2.4.3.jar
			slf4j-api-1.6.1.jar
			slf4j-log4j12-1.6.1.jar
			log4j-1.2.17.jar
			
		ehcache.xml
		
			<?xml version="1.0" encoding="UTF-8" ?>
			<ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
				xsi:noNamespaceSchemaLocation="ehcache.xsd">
				<cache name="domain.Guide" 
					maxElementsInMemory="1000" 
					eternal="true" 
					<!-- Configure timeToIdleSeconds and timeToLiveSeconds if there is a probability of more than one user modifying the entity at the same time -->
					timeToIdleSeconds="..."  
					timeToLiveSeconds="..." 
					overflowToDisk="false"
				</cache>
			</ehcache>
		
		 When entities cached in the second level cache are updated, Hibernate invalidates them and add the updated data.
		 
	To manually invalidate the cached data of a persistent class:
	emf.evictEntity(domain.Guide2);		//Invalidate all elements
	emf.evictEntity(domain.Guide2, 2L);	//Invalidate only one element
	
	StatistcsAPI: Monitors the second level cache.
	
	Cache Concurrency Strategy: A cache concurrency strategy defines a transaction isolation level for an entry in a cache region.
		
		@Cacheable uses CacheConcurrencyStrategy.READ_WRITE. Default and it is equivalent to READ_COMMITTED transaction isolation level.
		
		Types
		
			- TRANSACTIONAL: cluster, read-mostly data; equivalent to REPEATABLE_READ
			- READ_WRITE: read mostly data equivalent to READ_COMMITTED
			- NONSTRICT_READ_WRITE : data is hardly ever changes
			- READ_ONLY: data is never modified
		
		
			Single JVM - EhCache
				READ_WRITE
				NONSTRICT_READ_WRITE
				READ_ONLY
				
			Cluster of JVM - TreeCache
				TRANSACTIONAL
				
		@Cacheable does not have an option to configure other CacheConcurrencyStrategy.
		
		@org.hibernate.annotations.Cache(usage=CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
		
	Process Scope - Cluster Scope
	
		Process Scope
			- Single JVM
			- READ_ONLY, NONSTRICT_READ_WRITE, READ_WRITE
			- EhCache
		
		Cluster Scope
			- Cluster of JVMs
			- Transactional
			- TreeCache from JBOSS (Replicated clustered cache)
		
	Caching Associations (in Second level cache)	
		
		By default associated objects are not cached.
		The reason to cache associations is to avoid extra calls to the database.
		The second level caching is enabled not only on the class-by-class basis, but the collection-by-collection basis as well.
		If a persistent object contains associated objects in a collection, the collection can also be cached explicitly.
		
Best practices

	1. Declare identifier properties on persistent classes.
	
	2. Identify natural/business keys.
	
	3. Do not treat exceptions as recoverable.
	
	4. Prefer lazy fetching for associations. If you need to load a collection eagerly use a left join fetch.
	
	5. Prefer bidirectional associations. In a large application, almost all associations must be navigable
		in both directions in queries
		
	6. Use bind variables.
	
		In JDBC always replace non-constant values by ?
		If using JPQL used named parameters
	
	7. Using second level caching for those entity classes that represented
		
		Good candidates: 
		
			Data that changes rarely.
			Noncritical data (for example content management data)
			Data that's local to the application and not modified by other applications.
			
		Bad candidates:
		
			Data taht is updated often.
			Financial data, where decisions must be based on the latest update.
			Data that is shared with and/or written by other applications.
			
	
	